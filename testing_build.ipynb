{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kfp --upgrade\n",
    "# !pip install --upgrade google-cloud-storage\n",
    "# !pip3 install google-cloud-aiplatform --upgrade\n",
    "# !pip3 install google-cloud-pipeline-components --upgrade\n",
    "# !pip install --upgrade gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Operation \"operations/acf.p2-287876211803-6f3ceda3-3071-434d-b46b-ac97d7eed47c\" finished successfully.\n"
     ]
    }
   ],
   "source": [
    "# !gcloud services enable compute.googleapis.com \\\n",
    "#                        containerregistry.googleapis.com \\\n",
    "#                        aiplatform.googleapis.com \\\n",
    "#                        cloudbuild.googleapis.com \\\n",
    "#                        cloudfunctions.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=W64za8nexwnW1JTs6PF63I0wSAkGBz&access_type=offline&code_challenge=0XeQHg13p4kVNcHdJHytJidT63WX6ktzAXyOLYHkBmg&code_challenge_method=S256\n",
      "\n",
      "\n",
      "You are now logged in as [himanshusainigcp@gmail.com].\n",
      "Your current project is [buoyant-algebra-355618].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: vertextesting-355712\n",
      "NAME: vertextesting\n",
      "PROJECT_NUMBER: 287876211803\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth login\n",
    "!gcloud projects list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=ncbIw0oAJHRyAFbjy1rY7OLSXqquIS&access_type=offline&code_challenge=p5hQKd3FxuDihJj2yeyMKMCyDoc3SulmQBkJnW_SgcY&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [C:\\Users\\hsain\\AppData\\Roaming\\gcloud\\application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"vertextesting-355712\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project vertextesting-355712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"vertextesting-355712\"\n",
    "REGION = \"us-central1\" #though us-central is cheaper\n",
    "# through gstutil we access storage\n",
    "PIPELINE_ROOT = \"gs://vertextestingpipeline/pipeline_root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component)\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"pandas\",\"sklearn\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"getting_data.yaml\"\n",
    ")\n",
    "def get_data(\n",
    "    train_dataset : Output[Dataset],\n",
    "    test_dataset : Output[Dataset]\n",
    "):\n",
    "\n",
    "    from sklearn import datasets\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    data_raw = datasets.load_breast_cancer()\n",
    "    data = pd.DataFrame(data_raw.data, columns=data_raw.feature_names)\n",
    "    data['target'] = data_raw.target\n",
    "\n",
    "    train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "    train.to_csv(train_dataset.path)\n",
    "    test.to_csv(test_dataset.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"pandas\",\"sklearn\",\"xgboost\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"training.yaml\"\n",
    ")\n",
    "def training(\n",
    "    train_data : Input[Dataset],\n",
    "    test_data : Input[Dataset],\n",
    "    model : Output[Model],\n",
    "    metrics :Output[ClassificationMetrics],\n",
    "    smetrics: Output[Metrics],\n",
    "    threshold_value_str : str\n",
    ") -> NamedTuple(\"Outputs\", [(\"accuracy\", str)]):\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    import pandas as pd\n",
    "    import json\n",
    "\n",
    "    data = pd.read_csv(train_data.path)\n",
    "\n",
    "    model_xg = XGBClassifier(\n",
    "        objective=\"binary:logistic\"\n",
    "    )\n",
    "    model_xg.fit(\n",
    "        data.drop(columns=[\"target\"]),\n",
    "        data.target,\n",
    "    )\n",
    "\n",
    "    score = model_xg.score(\n",
    "        data.drop(columns=[\"target\"]),\n",
    "        data.target,\n",
    "    )\n",
    "\n",
    "    model.metadata[\"train_score\"] = float(score)\n",
    "    model.metadata[\"framework\"] = \"XGBoost\"\n",
    "\n",
    "    model_xg.save_model(model.path+\".bst\")\n",
    "\n",
    "    from sklearn.metrics import roc_curve, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "    \n",
    "    data_test = pd.read_csv(test_data.path)\n",
    "\n",
    "    y_scores =  model_xg.predict_proba(data_test.drop(columns=[\"target\"]))[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(\n",
    "         y_true=data_test.target.to_numpy(), y_score=y_scores, pos_label=True\n",
    "    )\n",
    "    metrics.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n",
    "    \n",
    "    y_pred = model_xg.predict(data_test.drop(columns=[\"target\"]))\n",
    "    \n",
    "    metrics.log_confusion_matrix(\n",
    "       [\"False\", \"True\"],\n",
    "       confusion_matrix(\n",
    "           data_test.target, y_pred\n",
    "       ).tolist(),  # .tolist() to convert np array to list.\n",
    "    )\n",
    "\n",
    "    accuracy = accuracy_score(data_test['target'],y_pred)\n",
    "    smetrics.log_metric(\"Accuracy\",accuracy)\n",
    "\n",
    "    def threshold_check(val1, val2):\n",
    "        cond = \"false\"\n",
    "        if val1 >= val2 :\n",
    "            cond = \"true\"\n",
    "        return cond\n",
    "        \n",
    "    threshold_value = json.loads(threshold_value_str)\n",
    "    deploy = threshold_check(accuracy,float(threshold_value[\"accuracy\"]))\n",
    "\n",
    "    return(str(deploy),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "\n",
    "\n",
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\", \"sklearn\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"deploy.yaml\"\n",
    ")\n",
    "def deploy_model(\n",
    "    model : Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model],\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project=project, location=region)\n",
    "    \n",
    "    ENDPOINT_NAME = \"cancerModel\"\n",
    "    \n",
    "    #Uploading model..\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"XGBoost_Model\",\n",
    "        artifact_uri = model.uri.replace(\"model\",\"\"),\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-5:latest\",\n",
    "        serving_container_health_route=f\"/v1/models/cancer\",\n",
    "        description = \"1st version - Cancer\",\n",
    "        version_description=\"Cancer xgboost model\",\n",
    "    )\n",
    "\n",
    "    def create_endpoint():\n",
    "        endpoints = aiplatform.Endpoint.list(\n",
    "        filter='display_name=\"{}\"'.format(ENDPOINT_NAME),\n",
    "        order_by='create_time desc',\n",
    "        project=project, \n",
    "        location=region,\n",
    "        )\n",
    "        if len(endpoints) > 0:\n",
    "            endpoint = endpoints[0]  # most recently created\n",
    "        else:\n",
    "            endpoint = aiplatform.Endpoint.create(\n",
    "            display_name=ENDPOINT_NAME, project=project, location=region\n",
    "        )\n",
    "        return endpoint\n",
    "\n",
    "    main_endpoint = create_endpoint()\n",
    "\n",
    "    deployed_model_id = main_endpoint.list_models()\n",
    "    \n",
    "    if deployed_model_id is not None:\n",
    "        for deployed_model in deployed_model_id:\n",
    "            main_endpoint.undeploy(deployed_model_id=deployed_model.id)\n",
    "\n",
    "\n",
    "    endpoint_deploy = deployed_model.deploy(machine_type=\"n1-standard-2\", endpoint=main_endpoint, min_replica_count=1, max_replica_count=2, deployed_model_display_name=\"Cancer model one\")\n",
    "    # endpoint_deploy.wait()\n",
    "\n",
    "    vertex_endpoint.uri = main_endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name\n",
    "\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"XGBoost_Model\",\n",
    "        artifact_uri = model.uri.replace(\"model\",\"\"),\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-5:latest\",\n",
    "        serving_container_health_route=f\"/v1/models/cancer\",\n",
    "        description = \"2nd version - Cancer\",\n",
    "        version_description=\"Cancer xgboost model\",\n",
    "    )\n",
    "\n",
    "    print(\"Model ID.............\")\n",
    "    print(main_endpoint.list_models()[0].id)\n",
    "\n",
    "    deployed_model_id = main_endpoint.list_models()[0].id\n",
    "\n",
    "    endpoint_deploy = deployed_model.deploy(machine_type=\"n1-standard-2\", endpoint=main_endpoint, min_replica_count=1, max_replica_count=1, deployed_model_display_name=\"Cancer model two\", traffic_split={\"0\":70,deployed_model_id:30})\n",
    "    # endpoint_deploy.wait()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    name=\"getting-data\",\n",
    "    description=\"Getting data of breast cancer\",\n",
    ")\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "    pulled_data = get_data().set_cpu_limit(\"1\").set_memory_limit(\"2\")\n",
    "    train_eval = training(train_data=pulled_data.outputs[\"train_dataset\"], test_data=pulled_data.outputs[\"test_dataset\"], threshold_value_str={\"accuracy\":0.90}).set_cpu_limit(\"1\").set_memory_limit(\"2\").after(pulled_data)\n",
    "    \n",
    "    with dsl.Condition(\n",
    "        train_eval.outputs[\"accuracy\"] == \"true\",\n",
    "        name=\"Testing Threshold\"\n",
    "    ):\n",
    "        upload_model = deploy_model(model=train_eval.outputs[\"model\"],project=project, region=region).set_cpu_limit(\"1\").set_memory_limit(\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hsain\\.conda\\envs\\vertexai\\lib\\site-packages\\kfp\\v2\\compiler\\compiler.py:1278: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='xgb_pipe.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/287876211803/locations/us-central1/pipelineJobs/getting-data-20220709190410\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/287876211803/locations/us-central1/pipelineJobs/getting-data-20220709190410')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/getting-data-20220709190410?project=287876211803\n"
     ]
    }
   ],
   "source": [
    "start_pipeline = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"pipeline-breast-cancer\",\n",
    "    template_path=\"xgb_pipe.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    project=PROJECT_ID,\n",
    "    enable_caching=True,\n",
    "    location=REGION,\n",
    ")\n",
    "\n",
    "start_pipeline.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully saved requirements file in e:\\Practicing Vertex AI\\requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!pipreqs --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_id = \"2267236956939223040\"\n",
    "location = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[0.8395712375640869], deployed_model_id='3088558948748361728', model_version_id='', model_resource_name='projects/287876211803/locations/us-central1/models/6403076333097713664', explanations=None)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample input list for prediction data\n",
    "from traceback import print_tb\n",
    "\n",
    "\n",
    "instance = [[14.6,23.29,93.97]]\n",
    "\n",
    "PROJECT_ID = \"vertextesting-355712\"\n",
    "\n",
    "def endpoint_predict(\n",
    "    project: str, location: str, instances: list, endpoint: str\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(endpoint)\n",
    "\n",
    "    prediction = endpoint.predict(instances=instances)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "endpoint_predict(PROJECT_ID, location, instance, endpoint_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('vertexai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93ef861f6fb13f1119ec8f205c9f1e3ca43f5c8db546d4067888a011b7c36bf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
